---
title: "Classification of Stars, Galaxies and Quasars"
author: "Enio Linhares Junior"
date: "5/19/2019"
output:
  html_document: 
    code_folding: hide
    fig_caption: yes
    fig_height: 6
    keep_md: yes
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: no
---

## 1 Introduction  

### 1.1 Content  

The Sloan Digital Sky Survey (SDSS) offers public data of space observations and the task here is to build a model that is able to predict the different classes of objects (Stars, Galaxies and Quasars) based on the data acquired through the scientific equipment.
The data consists of 10,000 observations of space taken by the SDSS. Every observation is described by 17 feature columns and 1 class column which identifies it to be either a star, galaxy or quasar.  
Our model achieved an **accuray** of 0.9915019

### 1.2 Feature Description  

The table results from a query which joins two tables (actuaclly views): "PhotoObj" which contains photometric data and "SpecObj" which contains spectral data.

During our data exploratory analysis we will be explaining the features as they appear.

*The data released by the SDSS is under public domain. Its taken from the current data release RD14.*  

## 2 Downloading Installing and Starting R

### 2.1 Installing the DataSet  

The url can be found here: https://www.kaggle.com/lucidlenn/sloan-digital-sky-survey/version/1

### 2.2 Libraries used  
```{r packages, message = FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(ggcorrplot)) install.packages("ggcorrplot", repos = "http://cran.us.r-project.org")
if(!require(RSNNS)) install.packages("RSNNS", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
if(!require(kernlab)) install.packages("kernlab", repos = "http://cran.us.r-project.org")
if(!require(cowplot)) install.packages("cowplot", repos = "http://cran.us.r-project.org")
```

```{r libraries, message = FALSE}
library(tidyverse)
library(data.table)
library(caret)
library(ggplot2)
library(ggcorrplot)
library(RSNNS)
library(randomForest)
library(ggcorrplot)
library(kernlab)
library(cowplot)
```

## 3 Load The Data

```{r dataset, message = FALSE}
sky.df <- fread(file = "Skyserver_SQL2_27_2018 6_51_39 PM.csv", sep=",") # load the data and save for use.
```

### 3.1 Create a Validation Dataset
```{r}
# create a list of 80% of the rows in the original dataset we can use for training
index <- createDataPartition(sky.df$class, p=0.8, list=FALSE)
# select 20% of the data for validation
validation <- sky.df[-index,]
# use the remaining 80% of data to training and testing the models
sky.train <- sky.df[index,]
```

## 4 Summarize Dataset  
### 4.1 Structure, summary, NA's check, and dimensions
```{r summarize}
str(sky.train)
summary(sky.train)
colSums(is.na(sky.train)) # any NA's?
dim(sky.train)
```

### 4.2 Types of attributes
```{r types of atributes}
sapply(sky.train, class) # checking the class of every feature
```

The "class" column is our response variable. Since this is a classification problem, we will transform it in a factor with three levels:  
```{r factor class}
sky.train$class <- as.factor(sky.train$class)
levels(sky.train$class)
validation$class <- as.factor(validation$class)
levels(validation$class)
```

### 4.3 Class distribution

Summarize the class distribution:
```{r}
percentage <- prop.table(table(sky.train$class)) * 100
cbind(freq=table(sky.train$class), percentage=percentage)
```
### 4.4 Statistical Summary
```{r}
summary(sky.train)
```
We observe here two different things that the data preparation and exploratory analysis tells us:  
- The class distribution is not even and this could be solved later using the SMOTE function which equalizes the classes proportion.  
- The numeric columns are not on the same scale.  
As a first step we decided to explore the data "as it is" and later, when we build the model, we evaluate the use of the SMOTE function and equalize the classes. 

## 5 Visualization
### 5.1 Grouped Features

The **Thuan-Gunn** astronomic magnitude system. u, g, r, i, z represent the response of the 5 bands of the telescope:  
```{r}
thuan_gunn <- c("u", "g", "r", "i", "z")
```
- u = better of DeV/Exp magnitude fit
- g = better of DeV/Exp magnitude fit
- r = better of DeV/Exp magnitude fit
- i = better of DeV/Exp magnitude fit
- z = better of DeV/Exp magnitude fit  

*Field:*   
Run, rerun, camcol and field are features which describe a field within an image taken by the SDSS. A field is basically a part of the entire image corresponding to 2048 by 1489 pixels. A field can be identified by: - run number, which identifies the specific scan, - the camera column, or "camcol," a number from 1 to 6, identifying the scanline within the run, and - the field number. The field number typically starts at 11 (after an initial rampup time), and can be as large as 800 for particularly long runs. - An additional number, rerun, specifies how the image was processed.
```{r}
field_feat <- c("run", "rerun", "camcol", "field")
```
- run = Run Number
- rereun = Rerun Number
- camcol = Camera column
- field = Field number 

*Skies or Sky:*  
Right ascension (abbreviated RA) is the angular distance measured eastward along the celestial equator from the Sun at the March equinox to the hour circle of the point above the earth in question. When paired with declination (abbreviated dec), these astronomical coordinates specify the direction of a point on the celestial sphere (traditionally called in English the skies or the sky) in the equatorial coordinate system. [Source](https://en.wikipedia.org/wiki/Right_ascension).
```{r}
skies <- c("ra", "dec")
```

*Remaining features:*  

- redshift = Final Redshift
- plate = plate number
- mjd = MJD of observation
- fiberid = fiber ID  
In physics, redshift happens when light or other electromagnetic radiation from an object is increased in wavelength, or shifted to the red end of the spectrum.  

Each spectroscopic exposure employs a large, thin, circular metal plate that positions optical fibers via holes drilled at the locations of the images in the telescope focal plane. These fibers then feed into the spectrographs. Each plate has a unique serial number, which is called plate in views such as SpecObj in the CAS.  

Modified Julian Date, used to indicate the date that a given piece of SDSS data (image or spectrum) was taken.  

The SDSS spectrograph uses optical fibers to direct the light at the focal plane from individual objects to the slithead. Each object is assigned a corresponding fiberID.  
```{r}
equipment_feat <- c("redshift", "plate", "mjd",
                    "fiberid") # These features are related to the measurement equipment
```  

*Class and Identification:*  
The class identifies an object to be either a galaxy, star or quasar. This will be the response variable which we will be trying to predict.
- View "SpecObj"
- specobjid = Object Identifier
- class = object class (galaxy, star or quasar object)  

### 5.2 Univariate Plots
The *class* distribution can now be visualized on the training set:  
```{r classes dist}
x <- sky.train[,-c(1, 13, 14, 16, 17)]
y <- sky.train$class # split input and output
ggplot(sky.train, aes(class, fill = class)) +
  geom_bar() # plot the classes
```  
We need a different approach now: normalize the data to have all the numeric features between 0 and 1 to be able to compare them and understand better the data.  
```{r normalize}
# normalize using the package 'RSNNS'
set.seed(2205)
sky.train.norm <- normalizeData(sky.train[,-c(1, 13, 14)], type = "0_1")
sky.train.norm <- as.data.frame(sky.train.norm)
summary(sky.train.norm) # check the normalization
```
Tidying the normalized data:
```{r tidying normalized}
names_sky.train <- names(sky.train[,-c(1, 13, 14)]) # add the names non-numeric columns back to the df.
names(sky.train.norm) <- names_sky.train
# now we add back the columns that were not included in the normalization.
sky.train.norm <- add_column(sky.train.norm, objid = sky.train$objid)
sky.train.norm <- add_column(sky.train.norm, specobjid = sky.train$specobjid)
sky.train.norm <- add_column(sky.train.norm, class = sky.train$class)
head(sky.train.norm, 2)
```
plotting with the normalized data:  
```{r feature plot}
x <- sky.train.norm[,-c(9, 16:18)]
y <- sky.train.norm$class
featurePlot(x = sky.train.norm[, c("u", "g", "r", "i", "z")], y = y, plot="box",
            main = "Thuan_gunn Group")
featurePlot(x = sky.train.norm[, c("run", "camcol", "field")], y = y, plot="box",
            main = "Field Features (excluded 'rerun')")
featurePlot(x = sky.train.norm[, c("redshift", "plate", "mjd", "fiberid")], y = y, plot="box",
            main = "Equipment Features")
featurePlot(x = sky.train.norm[, c("ra", "dec")], y = y, plot="box",
            main = "Skies / Sky Feature")
```
This visualization is useful for us to notice that there are clearly different distributions of the attributes for each class value and to identify the outliers (noise).  
There seems to be great variability in the 'mjd' and 'plate' parameters.  
The variability found in the 'Thuann_gunn' group will be kept 'as it is' and we will deal with it only in case we need to improve our model.  

### 5.3 Variables importance  
Running a model with *randomForest* to check the variables importance:
```{r variable importance}
set.seed(2205)
rf.sky.train <- randomForest(class ~ ., data = sky.train[, -c(1, 10, 13)])
imp.df <- importance(rf.sky.train) # importance of the features
imp.df <- data.frame(features = row.names(imp.df), MDG = imp.df[,1])
imp.df <- imp.df[order(imp.df$MDG, decreasing = TRUE),]
ggplot(imp.df, aes(x = reorder(features, MDG), y = MDG, fill = MDG)) +
  geom_bar(stat = "identity") + labs (x = "Features", y = "Mean Decrease Gini (MDG)") +
  coord_flip()
```  
The *plate* seems to have importance when predicting. This could be a noisy parameter since we have different plates measuring the waves.  
The *MJD* seems to be important as well. Could those two features make the difference in the model?  

Running a PCA analysis to check the variables importance (we are excluding 2 constant features and the factors)
```{r PCA}
PCA.sky.train <- prcomp(sky.train[, -c(1, 10, 13, 14)])
summary(PCA.sky.train)
```  
We notice that the first 6 components respond by 99.99% of the data.  
Considering that the number of features is not so big, we could use all the features already considered by the PCA analysis or use only the first 6 features.  

The MDG definition:
"Because Random Forests are an ensemble of individual Decision Trees, Gini Importance can be leveraged to calculate Mean Decrease in Gini, which is a measure of variable importance for estimating a target variable.  
Mean Decrease in Gini is the average (mean) of a variableâ€™s total decrease in node impurity, weighted by the proportion of samples reaching that node in each individual decision tree in the random forest. This is effectively a measure of how important a variable is for estimating the value of the target variable across all of the trees that make up the forest. A higher Mean Decrease in Gini indicates higher variable importance. Variables are sorted and displayed in the Variable Importance Plot created for the Random Forest by this measure.  
The most important variables to the model will be highest in the plot / list and have the largest Mean Decrease in Gini Values, conversely, the least important variable will be lowest in the plot, and have the smallest Mean Decrease in Gini values.
```{r imp table}
rownames(imp.df) <- NULL
imp.df %>% knitr::kable(caption = "Importance")
```  

## 6 Defining the dataset for the model:
### 6.1 Features Selection  

We will select the features to be part of the dataset that will be evaluated.  

```{r coorelation plot}
sky.model <- sky.train[, -c(1, 10, 13)]
corr <- round(cor(sky.model[, -11], use = "complete.obs"), 2)
ggcorrplot(corr, hc.order = TRUE, 
           type = "lower", 
           lab = TRUE, 
           lab_size = 3, 
           method="circle", 
           colors = c("red1", "honeydew", "green2"), 
           title="Correlation of Numeric Features", 
           ggtheme=theme_bw)
```  

Although the *plate* and *mjd* feature show with a high importance in the MDG evaluation, their correlation is based on the multicollinearity adn they are not independent because every *plate* is linked to a *fiberid* and a *mjd*.  
For this reason we decided to **exclude** these features from the dataset that will be used on the model.  

```{r grid1}
theme1 <- theme(axis.text.x = element_text(size = 8, angle = 90, hjust = 0.5, vjust = 0.5),
                axis.text.y = element_text(size = 8, angle = 0, hjust = 0.5, vjust = 0.5),
                axis.title.x = element_text(size = 8, angle = 0, hjust = 0.5, vjust = 0.5),
                axis.title.y = element_text(size = 8, angle = 90, hjust = 0.5, vjust = 0.5),
               legend.position="top", legend.text = element_text(size = 6),
               legend.title = element_text(size = 6))
plot_grid(ggplot(sky.train.norm, aes(plate, mjd, col = class)) + geom_point() + theme1,
          ggplot(sky.train.norm, aes(plate, fiberid, col = class)) + geom_point() + theme1,
          ggplot(sky.train.norm, aes(mjd, fiberid, col = class)) + geom_point() + theme1,
          align = "h")
```  

Selecting the columns:  

```{r sky model}
sky.model <- sky.train[,c("redshift", "z", "i", "g", "r", "u", "class")] # selecting the columns we need
```  

As a last check we will visualize the **redshift** variable because it showed a greater importance compared to the other variables.  
This is the interaction between "redshift" and the other selected features (note: for better visualization we used the normalized dataset to make it easier the comparison).  

```{r grid2}
plot_grid(ggplot(sky.train.norm, aes(z, redshift, col = class)) + geom_point() + theme1, 
          ggplot(sky.train.norm, aes(i, redshift, col = class)) + geom_point() + theme1,
          ggplot(sky.train.norm, aes(g, redshift, col = class)) + geom_point() + theme1,
          ggplot(sky.train.norm, aes(r, redshift, col = class)) + geom_point() + theme1,
          ggplot(sky.train.norm, aes(u, redshift, col = class)) + geom_point() + theme1,
          align = "h") # Thuann_Gunn group
```  

We can see on the plot above that the "redshift" how important it is, especially in the low wave length values showing a higher concentration forthe QSO making this feature an important observation for the "class" of the object to be predicted.  

Another comprison between redshift and features that have shown to be correlated in the previous analysis that have not been considered for the final model but those features have shown some correlation with the redshift feature:  

```{r grid3}
plot_grid(ggplot(sky.train.norm, aes(dec, redshift, col = class)) + geom_point() + theme1, 
          ggplot(sky.train.norm, aes(run, redshift, col = class)) + geom_point() + theme1,
          ggplot(sky.train.norm, aes(field, redshift, col = class)) + geom_point() + theme1,
          ggplot(sky.train.norm, aes(ra, redshift, col = class)) + geom_point() + theme1,
          ggplot(sky.train.norm, aes(plate, redshift, col = class)) + geom_point() + theme1,
          align = "h")
```  

In all these visualizations we have noted the data "redshift" is concentrated for the GALAXY and STAR classes and that for the QSO class it covers a broader range  showing that the data has a greater variability when we consider it as a QSO class feature.  Despite the small class imbalance we considered this not to be enough difference to make use of the *SMOTE* library from the **DMwR** package to equalize the classes proportion. 

## 7 Evaluate some algorithms

### 7.1 Testing Harness

Run algorithms using 20-fold cross validation
```{r cv parameters}
control <- caret::trainControl(method="cv", number=20)
metric <- "Accuracy"
```

### 7.2 Build Models

The model to be evaluated will be:  
- Linear
- nonLinear
- Advanced  
```{r models}
# a) linear algorithms
set.seed(2205)
fit.lda <- caret::train(class ~ . , data=sky.model, method="lda", metric=metric, trControl=control)
# b) nonlinear algorithms
# CART
set.seed(2205)
fit.cart <- caret::train(class ~ . , data=sky.model, method="rpart", metric=metric, trControl=control)
# kNN
set.seed(2205)
fit.knn <- caret::train(class ~ . , data=sky.model, method="knn", metric=metric, trControl=control)
# c) advanced algorithms
# SVM
set.seed(2205)
fit.svm <- caret::train(class ~ . , data=sky.model, method="svmRadial", metric=metric, trControl=control)
# Random Forest
set.seed(2205)
fit.rf <- caret::train(class ~ . , data=sky.model, method="rf", metric=metric, trControl=control)
```  

### 7.3 Select best model

Summarizing the accuracy of the models:  
```{r results}
results <- resamples(list(lda=fit.lda, cart=fit.cart, knn=fit.knn, svm=fit.svm,
                          rf=fit.rf))
summary(results)
```  

Compare the accuracy of the models:  
```{r accuracy}
dotplot(results)
print(fit.rf)
```  
The Accuracy vs. predictors and variable importance:  
```{r}
plot(fit.rf)
plot(varImp(fit.rf))
```  


## 8 Make Predictions

### 8.1 Estimating the skill of RF (randomForest) on the validation dataset.

columns to be discarded:  
```{r}
validation.model <- validation[,c("redshift", "z", "i", "g", "r", "u", "class")]
```  
Predict:  
```{r}
set.seed(2205)
predictions <- predict(fit.rf, validation.model)
caret::confusionMatrix(predictions, validation.model$class)
```  

## 9 Results and Conclusion

The conclusion we came to is that the validation set cases are not so hard to predict and the data is well clustered around the classes.  
We tried to discard the "redshift" feature in order to maximize the weight of the other features in previuos models but we only achieved an Accuracy = 0.9305 in the train set and Accuracy = 0.9235 in the validation (test) set having many cases of False Positives around 10% FP's when predicting STAR (predicted GALAXY instead) and 9% FP's when predicting QSO in relation to the other two classes.  
The decision is to keep the "redshift" feature along with the Thuann_gunn group.  
The final Accuracy is 0.9915019  

*Notes:*  
- Time to run the whole code 6.31 mins  
- Computer used:  
    - MacBook Pro  
    - Processor: 2.4 GHz Intel Core i5  
    - Memory: 8 GB 1600 MHz DDR3  
    - Graphics: Intel Iris 1536 MB